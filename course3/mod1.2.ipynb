{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T05:30:06.986270Z",
     "start_time": "2025-06-12T05:24:35.009018Z"
    }
   },
   "source": [
    "!pip install nlpaug\n",
    "\n",
    "from nlpaug.augmenter.word import BackTranslationAug\n",
    "\n",
    "# Initialize the backtranslation augmenter (English -> French -> English)\n",
    "back_translation_aug = BackTranslationAug(from_model_name='facebook/wmt19-en-de', to_model_name='facebook/wmt19-de-en')\n",
    "\n",
    "# Example text to augment\n",
    "text = \"The weather is great today.\"\n",
    "\n",
    "# Perform backtranslation to create augmented text\n",
    "augmented_text = back_translation_aug.augment(text)\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"Augmented text:\", augmented_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nlpaug\r\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from nlpaug) (2.1.3)\r\n",
      "Requirement already satisfied: pandas>=1.2.0 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from nlpaug) (2.3.0)\r\n",
      "Requirement already satisfied: requests>=2.22.0 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from nlpaug) (2.32.3)\r\n",
      "Collecting gdown>=4.0.0 (from nlpaug)\r\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from gdown>=4.0.0->nlpaug) (4.13.4)\r\n",
      "Requirement already satisfied: filelock in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from gdown>=4.0.0->nlpaug) (3.18.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from pandas>=1.2.0->nlpaug) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from pandas>=1.2.0->nlpaug) (2025.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from requests>=2.22.0->nlpaug) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from requests>=2.22.0->nlpaug) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from requests>=2.22.0->nlpaug) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from requests>=2.22.0->nlpaug) (2025.4.26)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.7)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (4.13.2)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/phuonghqh/.pyenv/versions/3.12.10/envs/learnai/lib/python3.12/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\r\n",
      "Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\r\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: gdown, nlpaug\r\n",
      "Successfully installed gdown-5.2.0 nlpaug-1.1.11\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phuonghqh/.pyenv/versions/learnai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at facebook/wmt19-en-de and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at facebook/wmt19-de-en and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotImplementedError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnlpaug\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01maugmenter\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mword\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BackTranslationAug\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# Initialize the backtranslation augmenter (English -> French -> English)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m back_translation_aug = \u001B[43mBackTranslationAug\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfrom_model_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mfacebook/wmt19-en-de\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_model_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mfacebook/wmt19-de-en\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Example text to augment\u001B[39;00m\n\u001B[32m      9\u001B[39m text = \u001B[33m\"\u001B[39m\u001B[33mThe weather is great today.\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/nlpaug/augmenter/word/back_translation.py:61\u001B[39m, in \u001B[36mBackTranslationAug.__init__\u001B[39m\u001B[34m(self, from_model_name, to_model_name, name, device, batch_size, max_length, force_reload, verbose)\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, from_model_name=\u001B[33m'\u001B[39m\u001B[33mfacebook/wmt19-en-de\u001B[39m\u001B[33m'\u001B[39m, to_model_name=\u001B[33m'\u001B[39m\u001B[33mfacebook/wmt19-de-en\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     56\u001B[39m     name=\u001B[33m'\u001B[39m\u001B[33mBackTranslationAug\u001B[39m\u001B[33m'\u001B[39m, device=\u001B[33m'\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m'\u001B[39m, batch_size=\u001B[32m32\u001B[39m, max_length=\u001B[32m300\u001B[39m, force_reload=\u001B[38;5;28;01mFalse\u001B[39;00m, verbose=\u001B[32m0\u001B[39m):\n\u001B[32m     57\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(\n\u001B[32m     58\u001B[39m         action=\u001B[33m'\u001B[39m\u001B[33msubstitute\u001B[39m\u001B[33m'\u001B[39m, name=name, aug_p=\u001B[38;5;28;01mNone\u001B[39;00m, aug_min=\u001B[38;5;28;01mNone\u001B[39;00m, aug_max=\u001B[38;5;28;01mNone\u001B[39;00m, tokenizer=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m     59\u001B[39m         device=device, verbose=verbose, include_detail=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m     \u001B[38;5;28mself\u001B[39m.model = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfrom_model_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_model_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_model_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mto_model_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     62\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_length\u001B[49m\n\u001B[32m     63\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     64\u001B[39m     \u001B[38;5;28mself\u001B[39m.device = \u001B[38;5;28mself\u001B[39m.model.device\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/nlpaug/augmenter/word/back_translation.py:76\u001B[39m, in \u001B[36mBackTranslationAug.get_model\u001B[39m\u001B[34m(cls, from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001B[39m\n\u001B[32m     73\u001B[39m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_model\u001B[39m(\u001B[38;5;28mcls\u001B[39m, from_model_name, to_model_name, device=\u001B[33m'\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m'\u001B[39m, force_reload=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     75\u001B[39m               batch_size=\u001B[32m32\u001B[39m, max_length=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m---> \u001B[39m\u001B[32m76\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minit_back_translation_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfrom_model_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_model_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/nlpaug/augmenter/word/back_translation.py:25\u001B[39m, in \u001B[36minit_back_translation_model\u001B[39m\u001B[34m(from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001B[39m\n\u001B[32m     21\u001B[39m     BACK_TRANSLATION_MODELS[model_name].max_length = max_length\n\u001B[32m     23\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m BACK_TRANSLATION_MODELS[model_name]\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m model = \u001B[43mnml\u001B[49m\u001B[43m.\u001B[49m\u001B[43mMtTransformers\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc_model_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_model_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt_model_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mto_model_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     26\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_length\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     28\u001B[39m BACK_TRANSLATION_MODELS[model_name] = model\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/nlpaug/model/lang_models/machine_translation_transformers.py:28\u001B[39m, in \u001B[36mMtTransformers.__init__\u001B[39m\u001B[34m(self, src_model_name, tgt_model_name, device, silence, batch_size, max_length)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28mself\u001B[39m.tgt_model = AutoModelForSeq2SeqLM.from_pretrained(\u001B[38;5;28mself\u001B[39m.tgt_model_name)\n\u001B[32m     27\u001B[39m \u001B[38;5;28mself\u001B[39m.tgt_model.eval()\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtgt_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[38;5;28mself\u001B[39m.src_tokenizer = AutoTokenizer.from_pretrained(\u001B[38;5;28mself\u001B[39m.src_model_name)\n\u001B[32m     30\u001B[39m \u001B[38;5;28mself\u001B[39m.tgt_tokenizer = AutoTokenizer.from_pretrained(\u001B[38;5;28mself\u001B[39m.tgt_model_name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/transformers/modeling_utils.py:3851\u001B[39m, in \u001B[36mPreTrainedModel.to\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   3846\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m dtype_present_in_args:\n\u001B[32m   3847\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   3848\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   3849\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m `dtype` by passing the correct `torch_dtype` argument.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   3850\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m3851\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001B[39m, in \u001B[36mModule.to\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1352\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1353\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1355\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    913\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    914\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m915\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    918\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    919\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    920\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    925\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    926\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    913\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    914\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m915\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    918\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    919\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    920\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    925\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    926\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    913\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    914\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m915\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    918\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    919\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    920\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    925\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    926\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    938\u001B[39m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[32m    939\u001B[39m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[32m    940\u001B[39m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     param_applied = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    943\u001B[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001B[32m    945\u001B[39m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/learnai/lib/python3.12/site-packages/torch/nn/modules/module.py:1348\u001B[39m, in \u001B[36mModule.to.<locals>.convert\u001B[39m\u001B[34m(t)\u001B[39m\n\u001B[32m   1346\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1347\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) == \u001B[33m\"\u001B[39m\u001B[33mCannot copy out of meta tensor; no data!\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1348\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[32m   1349\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1350\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mwhen moving module from meta to a different device.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1351\u001B[39m         ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1352\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1353\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[31mNotImplementedError\u001B[39m: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device."
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
