{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d54da7",
   "metadata": {},
   "source": [
    "In this activity, you will implement backward elimination, a feature selection technique that helps you identify the most important features for your ML model. Backward elimination starts with all features and progressively removes the least significant ones, leading to a more efficient model. The goal of this activity is to help you apply this technique to a dataset and refine your model by eliminating irrelevant features.\n",
    "\n",
    "By the end of this activity, you'll be able to:\n",
    "\n",
    "Implement backward elimination: identify and remove the least significant features from a dataset.\n",
    "\n",
    "Apply statistical modeling: fit a linear regression model using the statsmodels library and interpret the p-values to determine feature significance.\n",
    "\n",
    "Refine and simplify models: analyze the impact of removing irrelevant features on model performance and interpret the results to improve model efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecef46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d017d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "data = {\n",
    "    'StudyHours': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'PrevExamScore': [30, 40, 45, 50, 60, 65, 70, 75, 80, 85],\n",
    "    'Pass': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # 0 = Fail, 1 = Pass\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target variable\n",
    "X = df[['StudyHours', 'PrevExamScore']]\n",
    "y = df['Pass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39b13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to the model (for the intercept)\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b5ce1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   Pass   R-squared:                       0.758\n",
      "Model:                            OLS   Adj. R-squared:                  0.688\n",
      "Method:                 Least Squares   F-statistic:                     10.94\n",
      "Date:                Wed, 04 Jun 2025   Prob (F-statistic):            0.00701\n",
      "Time:                        14:32:42   Log-Likelihood:               -0.17258\n",
      "No. Observations:                  10   AIC:                             6.345\n",
      "Df Residuals:                       7   BIC:                             7.253\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -0.3333      1.464     -0.228      0.826      -3.796       3.129\n",
      "StudyHours        0.1515      0.324      0.468      0.654      -0.615       0.918\n",
      "PrevExamScore  6.939e-18      0.054   1.29e-16      1.000      -0.127       0.127\n",
      "==============================================================================\n",
      "Omnibus:                        0.086   Durbin-Watson:                   1.491\n",
      "Prob(Omnibus):                  0.958   Jarque-Bera (JB):                0.311\n",
      "Skew:                          -0.000   Prob(JB):                        0.856\n",
      "Kurtosis:                       2.136   Cond. No.                     1.01e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.01e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phuonghqh/.pyenv/versions/3.12.10/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:430: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=10 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using Ordinary Least Squares (OLS) regression\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Display the summary, including p-values for each feature\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df6dccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature: PrevExamScore with p-value: 0.9999999999999999\n",
      "Removing feature: const with p-value: 0.11419580126842226\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                   Pass   R-squared (uncentered):                   0.831\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.812\n",
      "Method:                 Least Squares   F-statistic:                              44.31\n",
      "Date:                Wed, 04 Jun 2025   Prob (F-statistic):                    9.31e-05\n",
      "Time:                        14:32:42   Log-Likelihood:                         -1.8294\n",
      "No. Observations:                  10   AIC:                                      5.659\n",
      "Df Residuals:                       9   BIC:                                      5.961\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "StudyHours     0.1039      0.016      6.656      0.000       0.069       0.139\n",
      "==============================================================================\n",
      "Omnibus:                        0.710   Durbin-Watson:                   1.054\n",
      "Prob(Omnibus):                  0.701   Jarque-Bera (JB):                0.557\n",
      "Skew:                          -0.000   Prob(JB):                        0.757\n",
      "Kurtosis:                       1.844   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phuonghqh/.pyenv/versions/3.12.10/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:430: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=10 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Define a significance level\n",
    "significance_level = 0.05\n",
    "\n",
    "# Perform backward elimination\n",
    "while True:\n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    # Get the highest p-value in the model\n",
    "    max_p_value = model.pvalues.max()\n",
    "    \n",
    "    # Check if the highest p-value is greater than the significance level\n",
    "    if max_p_value > significance_level:\n",
    "        # Identify the feature with the highest p-value\n",
    "        feature_to_remove = model.pvalues.idxmax()\n",
    "        print(f\"Removing feature: {feature_to_remove} with p-value: {max_p_value}\")\n",
    "        \n",
    "        # Drop the feature\n",
    "        X = X.drop(columns=[feature_to_remove])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Display the final model summary\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
