{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1854172",
   "metadata": {},
   "source": [
    "3. Example: Scraping information from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4f6020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Cloud-computing comparison - Wikipedia\n",
      "                      Provider Launched Block storage Assignable IPs  \\\n",
      "0        Google Cloud Platform     2013           Yes             No   \n",
      "1  Oracle Cloud Infrastructure     2014           Yes            Yes   \n",
      "2          Amazon Web Services     2006           Yes            Yes   \n",
      "3                    IBM Cloud     2005           Yes            Yes   \n",
      "4              Microsoft Azure     2010           Yes            Yes   \n",
      "\n",
      "  SMTP support IOPS Guaranteed minimum Security  \\\n",
      "0        No[1]                     Yes   Yes[2]   \n",
      "1          Yes                     Yes   Yes[5]   \n",
      "2   Partial[6]                     Yes   Yes[7]   \n",
      "3        No[9]                     Yes  Yes[10]   \n",
      "4      Yes[11]                     Yes  Yes[12]   \n",
      "\n",
      "                                           Locations             Notes  \n",
      "0  br, ca, cl, us, be, ch, de, es, fi, it, po, nl...  SMTP blocked.[4]  \n",
      "1  us, ca, br, de, uk, nl, ch, in, aus, jp, kr, saud                    \n",
      "2  us, ca, br, ie, de, uk, cn, sg, au, jp, kr, in...   List of bugs[8]  \n",
      "3  us, gb, fr, de, nl, in, au, hk, kr, it, jp, no...                    \n",
      "4  ca, us, br, ie, nl, de, uk, cn, au, jp, in, kr...  List of bugs[13]  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send an HTTP request to the webpage\n",
    "url = 'https://en.wikipedia.org/wiki/Cloud-computing_comparison'  \n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Print the title of the webpage to verify\n",
    "print(\"Title: \" + soup.title.text)\n",
    "\n",
    "# Find the table containing the data (selecting the first table by default)\n",
    "table = soup.find('table')\n",
    "\n",
    "# Extract table rows\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Extract headers from the first row (using <th> tags)\n",
    "headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "\n",
    "# Loop through the rows and extract data (skip the first row with headers)\n",
    "data = []\n",
    "for row in rows[1:]:  # Start from the second row onwards\n",
    "    cols = row.find_all('td')\n",
    "    cols = [col.text.strip() for col in cols]\n",
    "    data.append(cols)\n",
    "\n",
    "# Convert the data into a pandas DataFrame, using the extracted headers as column names\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df.head())  \n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('scraped_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
