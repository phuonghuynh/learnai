{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c243fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:47<00:00, 3.57MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 2000] loss: 2.204\n",
      "[Epoch 1, Batch 4000] loss: 1.820\n",
      "[Epoch 1, Batch 6000] loss: 1.670\n",
      "[Epoch 1, Batch 8000] loss: 1.581\n",
      "[Epoch 1, Batch 10000] loss: 1.536\n",
      "[Epoch 1, Batch 12000] loss: 1.467\n",
      "[Epoch 2, Batch 2000] loss: 1.412\n",
      "[Epoch 2, Batch 4000] loss: 1.392\n",
      "[Epoch 2, Batch 6000] loss: 1.358\n",
      "[Epoch 2, Batch 8000] loss: 1.319\n",
      "[Epoch 2, Batch 10000] loss: 1.316\n",
      "[Epoch 2, Batch 12000] loss: 1.262\n",
      "[Epoch 3, Batch 2000] loss: 1.227\n",
      "[Epoch 3, Batch 4000] loss: 1.216\n",
      "[Epoch 3, Batch 6000] loss: 1.228\n",
      "[Epoch 3, Batch 8000] loss: 1.189\n",
      "[Epoch 3, Batch 10000] loss: 1.196\n",
      "[Epoch 3, Batch 12000] loss: 1.181\n",
      "[Epoch 4, Batch 2000] loss: 1.115\n",
      "[Epoch 4, Batch 4000] loss: 1.110\n",
      "[Epoch 4, Batch 6000] loss: 1.116\n",
      "[Epoch 4, Batch 8000] loss: 1.127\n",
      "[Epoch 4, Batch 10000] loss: 1.105\n",
      "[Epoch 4, Batch 12000] loss: 1.118\n",
      "[Epoch 5, Batch 2000] loss: 1.033\n",
      "[Epoch 5, Batch 4000] loss: 1.059\n",
      "[Epoch 5, Batch 6000] loss: 1.050\n",
      "[Epoch 5, Batch 8000] loss: 1.041\n",
      "[Epoch 5, Batch 10000] loss: 1.036\n",
      "[Epoch 5, Batch 12000] loss: 1.045\n",
      "[Epoch 6, Batch 2000] loss: 0.952\n",
      "[Epoch 6, Batch 4000] loss: 0.975\n",
      "[Epoch 6, Batch 6000] loss: 1.021\n",
      "[Epoch 6, Batch 8000] loss: 0.994\n",
      "[Epoch 6, Batch 10000] loss: 1.001\n",
      "[Epoch 6, Batch 12000] loss: 1.004\n",
      "[Epoch 7, Batch 2000] loss: 0.911\n",
      "[Epoch 7, Batch 4000] loss: 0.937\n",
      "[Epoch 7, Batch 6000] loss: 0.952\n",
      "[Epoch 7, Batch 8000] loss: 0.950\n",
      "[Epoch 7, Batch 10000] loss: 0.944\n",
      "[Epoch 7, Batch 12000] loss: 0.992\n",
      "[Epoch 8, Batch 2000] loss: 0.873\n",
      "[Epoch 8, Batch 4000] loss: 0.900\n",
      "[Epoch 8, Batch 6000] loss: 0.919\n",
      "[Epoch 8, Batch 8000] loss: 0.918\n",
      "[Epoch 8, Batch 10000] loss: 0.915\n",
      "[Epoch 8, Batch 12000] loss: 0.924\n",
      "[Epoch 9, Batch 2000] loss: 0.821\n",
      "[Epoch 9, Batch 4000] loss: 0.851\n",
      "[Epoch 9, Batch 6000] loss: 0.871\n",
      "[Epoch 9, Batch 8000] loss: 0.885\n",
      "[Epoch 9, Batch 10000] loss: 0.901\n",
      "[Epoch 9, Batch 12000] loss: 0.904\n",
      "[Epoch 10, Batch 2000] loss: 0.814\n",
      "[Epoch 10, Batch 4000] loss: 0.812\n",
      "[Epoch 10, Batch 6000] loss: 0.834\n",
      "[Epoch 10, Batch 8000] loss: 0.879\n",
      "[Epoch 10, Batch 10000] loss: 0.855\n",
      "[Epoch 10, Batch 12000] loss: 0.872\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 61.66 %\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# build model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# training the model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# evaulate the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e7a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb244e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
