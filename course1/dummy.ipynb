{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dab417e",
   "metadata": {},
   "source": [
    "Step 1: Generate and load the dummy data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeac85fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature1  Feature2 Category  Target\n",
      "0  117.640523        32        A       1\n",
      "1  104.001572        70        B       1\n",
      "2  109.787380        85        C       0\n",
      "3  122.408932        31        D       1\n",
      "4  118.675580        13        A       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a dummy dataset\n",
    "np.random.seed(0)\n",
    "dummy_data = {\n",
    "    'Feature1': np.random.normal(100, 10, 100).tolist() + [np.nan, 200],  # Normally distributed with an outlier\n",
    "    'Feature2': np.random.randint(0, 100, 102).tolist(),  # Random integers\n",
    "    'Category': ['A', 'B', 'C', 'D'] * 25 + [np.nan, 'A'],  # Categorical with some missing values\n",
    "    'Target': np.random.choice([0, 1], 102).tolist()  # Binary target variable\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "df_dummy = pd.DataFrame(dummy_data)\n",
    "\n",
    "# Display the first few rows of the dummy dataset\n",
    "print(df_dummy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba89b99",
   "metadata": {},
   "source": [
    "Step 2: Load the preprocessing tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e8ce17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "def load_data(df):\n",
    "    return df\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    df = df.copy()\n",
    "    # Fill numeric columns with mean\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    # Fill non-numeric columns with mode\n",
    "    for col in df.select_dtypes(exclude=[np.number]).columns:\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "def remove_outliers(df):\n",
    "    z_scores = np.abs(stats.zscore(df.select_dtypes(include=[np.number])))\n",
    "    return df[(z_scores < 3).all(axis=1)]  # Remove rows with any outliers\n",
    "\n",
    "def scale_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    df[df.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(df.select_dtypes(include=[np.number]))\n",
    "    return df\n",
    "\n",
    "def encode_categorical(df, categorical_columns):\n",
    "    return pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "def save_data(df, output_filepath):\n",
    "    df.to_csv(output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93287aa3",
   "metadata": {},
   "source": [
    "Step 3: Preprocess the dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8b42a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2    Target  Category_A  Category_B  Category_C  \\\n",
      "0  1.698298 -0.519379  0.932936        True       False       False   \n",
      "1  0.338384  0.887380  0.932936       False        True       False   \n",
      "2  0.915276  1.442679 -1.071884       False       False        True   \n",
      "3  2.173747 -0.556399  0.932936       False       False       False   \n",
      "4  1.801501 -1.222759 -1.071884        True       False       False   \n",
      "\n",
      "   Category_D  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3        True  \n",
      "4       False  \n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df_preprocessed = load_data(df_dummy)\n",
    "\n",
    "# Handle missing values\n",
    "df_preprocessed = handle_missing_values(df_preprocessed)\n",
    "\n",
    "# Remove outliers\n",
    "df_preprocessed = remove_outliers(df_preprocessed)\n",
    "\n",
    "# Scale the data\n",
    "df_preprocessed = scale_data(df_preprocessed)\n",
    "\n",
    "# Encode categorical variables\n",
    "df_preprocessed = encode_categorical(df_preprocessed, ['Category'])\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(df_preprocessed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64dcd22",
   "metadata": {},
   "source": [
    "Step 4: Save the preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aab66813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Preprocessed data saved as preprocessed_dummy_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned and preprocessed DataFrame to a CSV file\n",
    "save_data(df_preprocessed, 'preprocessed_dummy_data.csv')\n",
    "\n",
    "print('Preprocessing complete. Preprocessed data saved as preprocessed_dummy_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be440047",
   "metadata": {},
   "source": [
    "Verifying the preprocessing steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e9e94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature1      0\n",
      "Feature2      0\n",
      "Target        0\n",
      "Category_A    0\n",
      "Category_B    0\n",
      "Category_C    0\n",
      "Category_D    0\n",
      "dtype: int64\n",
      "           Feature1      Feature2        Target\n",
      "count  1.010000e+02  1.010000e+02  1.010000e+02\n",
      "mean  -2.544032e-15 -3.407615e-17 -2.418308e-17\n",
      "std    1.004988e+00  1.004988e+00  1.004988e+00\n",
      "min   -2.606142e+00 -1.704018e+00 -1.071884e+00\n",
      "25%   -6.930755e-01 -6.674590e-01 -1.071884e+00\n",
      "50%    6.071482e-02 -1.861994e-01  9.329364e-01\n",
      "75%    6.663572e-01  8.503597e-01  9.329364e-01\n",
      "max    2.202524e+00  1.886919e+00  9.329364e-01\n",
      "   Feature1  Feature2    Target  Category_A  Category_B  Category_C  \\\n",
      "0  1.698298 -0.519379  0.932936        True       False       False   \n",
      "1  0.338384  0.887380  0.932936       False        True       False   \n",
      "2  0.915276  1.442679 -1.071884       False       False        True   \n",
      "3  2.173747 -0.556399  0.932936       False       False       False   \n",
      "4  1.801501 -1.222759 -1.071884        True       False       False   \n",
      "\n",
      "   Category_D  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3        True  \n",
      "4       False  \n",
      "Index(['Feature1', 'Feature2', 'Target', 'Category_A', 'Category_B',\n",
      "       'Category_C', 'Category_D'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values: \n",
    "print(df_preprocessed.isnull().sum())\n",
    "\n",
    "# Verify outlier removal:\n",
    "print(df_preprocessed.describe())\n",
    "print(df_preprocessed.head())\n",
    "print(df_preprocessed.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
